import {Context, Schema} from 'koishi'

// dr*
import {AIMessageChunk, BaseMessage} from '@langchain/core/messages'
import {ChatLunaPlugin} from 'koishi-plugin-chatluna/services/chat'
import {ChatGeneration, ChatGenerationChunk} from '@langchain/core/outputs'
import {ClientConfig} from "koishi-plugin-chatluna/llm-core/platform/config";
import {PlatformModelClient} from 'koishi-plugin-chatluna/llm-core/platform/client'
import {ModelRequester, ModelRequestParams} from "koishi-plugin-chatluna/llm-core/platform/api";
import {ModelInfo, ModelType} from "koishi-plugin-chatluna/llm-core/platform/types";
import {ChatLunaChatModel} from "koishi-plugin-chatluna/llm-core/platform/model";
import {ChatLunaError, ChatLunaErrorCode} from "koishi-plugin-chatluna/utils/error";

export const name = 'chatluna-cohere-playground-adapter'
export const usage = `## ğŸŒˆ ä½¿ç”¨

1. **è·å– API Keyï¼š**

- è®¿é—® [Cohere](https://dashboard.cohere.com/) æ³¨å†Œå¹¶ç™»å½•ã€‚
- ç™»å½•åå‰å¾€ [Cohere API Key](https://dashboard.cohere.com/api-keys) é¡µé¢ï¼Œå¤åˆ¶ \`Trial key\`ã€‚
  - \`Trial key\` å½¢å¦‚ \`iD35z8XuYzI1KKGoQ9EdzOSoV0SKPWLCHrUv61OD\`ã€‚

2. **é…ç½®æ’ä»¶ï¼š** åœ¨æœ¬æ’ä»¶è¯·æ±‚è®¾ç½®ä¸­æ·»åŠ è·å–åˆ°çš„ \`Trial key\`ã€‚

3. **å¼€å§‹ä½¿ç”¨ï¼** ç°åœ¨æ‚¨å¯ä»¥é€šè¿‡ Chatluna ä¸ Cohere AI è¿›è¡Œå¯¹è¯äº†ã€‚

- ä»…æ¨èä½¿ç”¨ \`command-r-plus\` æ¨¡å‹ï¼Œå…¶ä»–æ¨¡å‹ä¸äºˆç½®è¯„ã€‚
- \`Cohere\` æ¯ä¸ªè´¦å·æ¯æœˆæœ‰ 1000 æ¬¡å…è´¹è¯·æ±‚ï¼Œè¶…å‡ºåå°†æ— æ³•ä½¿ç”¨ã€‚
  - å°è´´å£«ï¼šä½¿ç”¨ [Gmail ä¸´æ—¶é‚®ç®±](https://www.emailtick.com/) æ³¨å†Œ Cohere è´¦å·ï¼Œä»¥è·å–æ›´å¤šå…è´¹è¯·æ±‚æ¬¡æ•°ã€‚`
export const inject = {
  required: ['chatluna'],
}

// pz*
export interface Config extends ChatLunaPlugin.Config {
  apiKeys: string[];
  temperature: number;
  k: number;
  p: number;
  frequency_penalty: number;
  presence_penalty: number;
  documents: Document[];
}

export const Config: Schema<Config> = Schema.intersect([
  ChatLunaPlugin.Config,
  Schema.object({
    apiKeys: Schema.array(
      Schema.string().role('secret').required()
    ).description('Cohere API Keysã€‚'),
  }).description('è¯·æ±‚è®¾ç½®'),
  Schema.object({
    k: Schema.number().max(500).min(0).default(0).description('k å‚æ•°ã€‚ç¡®ä¿åœ¨æ¯ä¸ªæ­¥éª¤ä¸­åªè€ƒè™‘æœ€æœ‰å¯èƒ½çš„ k ä¸ª tokensã€‚é»˜è®¤ 0ï¼ŒèŒƒå›´ 0-500ã€‚'),
    p: Schema.number().max(0.99).min(0.01).default(0.75).description('p å‚æ•°ã€‚ç¡®ä¿åœ¨æ¯ä¸€æ­¥ç”Ÿæˆæ—¶ï¼Œåªè€ƒè™‘æ€»æ¦‚ç‡è´¨é‡ä¸º p çš„å¯èƒ½æ€§æœ€å¤§çš„ tokensã€‚å¦‚æœ k å’Œ p éƒ½å¯ç”¨ï¼Œåˆ™ p åœ¨ k ä¹‹åæ‰§è¡Œã€‚é»˜è®¤ 0.75ã€‚èŒƒå›´ 0.01-0.99ã€‚ '),
    temperature: Schema.number().max(1).min(0).step(0.1).default(1).description('å›å¤æ¸©åº¦ï¼Œè¶Šé«˜è¶Šéšæœºã€‚éšæœºæ€§å¯ä»¥é€šè¿‡å¢åŠ  p å‚æ•°çš„å€¼æ¥è¿›ä¸€æ­¥æœ€å¤§åŒ–ã€‚èŒƒå›´ 0-1ã€‚'),
    frequency_penalty: Schema.number().max(1).min(0).step(0.1).default(0).description('é¢‘ç‡æƒ©ç½šã€‚ç”¨äºå‡å°‘ç”Ÿæˆçš„é‡å¤æ€§ã€‚å€¼è¶Šé«˜ï¼Œè¶Šéšæœºï¼Œä¸”è·Ÿ tokens é‡å¤å‡ºç°çš„æ¬¡æ•°æˆæ¯”ä¾‹ã€‚é»˜è®¤ 0ï¼ŒèŒƒå›´ 0-1ã€‚'),
    presence_penalty: Schema.number().max(1).min(0).step(0.1).default(0).description('å­˜åœ¨æƒ©ç½šã€‚ç”¨äºå‡å°‘ç”Ÿæˆçš„é‡å¤æ€§ã€‚ä¸é¢‘ç‡æƒ©ç½šç±»ä¼¼ï¼Œä½†è¿™ç§æƒ©ç½šé€‚ç”¨äºæ‰€æœ‰å·²ç»å‡ºç°çš„ tokensï¼Œæ— è®ºå®ƒä»¬çš„é¢‘ç‡ï¼ˆå‡ºç°æ¬¡æ•°ï¼‰å¦‚ä½•ã€‚é»˜è®¤ 0ï¼ŒèŒƒå›´ 0-1ã€‚'),
    documents: Schema.array(Schema.object({
      title: Schema.string(),
      text: Schema.string(),
    })).role('table').description(`æ–‡æ¡£åˆ—è¡¨ã€‚ä¸€ä¸ªæ¨¡å‹å¯ä»¥å¼•ç”¨çš„ç›¸å…³æ–‡æ¡£åˆ—è¡¨ï¼Œä»¥ç”Ÿæˆæ›´å‡†ç¡®çš„å›å¤ã€‚æ¯ä¸ªæ–‡æ¡£éƒ½æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²-å­—ç¬¦ä¸²å­—å…¸ã€‚ç¤ºä¾‹ï¼š
\`[
  {â€œtitleâ€ï¼šâ€œé«˜ä¼é¹…â€ï¼Œâ€œtextâ€ï¼šâ€œå¸ä¼é¹…æœ€é«˜ã€‚" },
  {â€œtitleâ€ï¼šâ€œä¼é¹…æ –æ¯åœ°â€ï¼Œâ€œtextâ€ï¼šâ€œå¸ä¼é¹…åªç”Ÿæ´»åœ¨å—ææ´²ã€‚" },
]\` `),
  }).description('æ¨¡å‹è®¾ç½®')
]) as any


// jk*
interface Result {
  chat_history: { role: string; message: string }[];
  preamble: string;
}

interface GetKeyResponse {
  rawKey: string;
}

interface Document {
  title: string;
  text: string;
}

interface ChatRequest {
  message: string;
  stream: boolean;
  chat_history?: any[];
  model?: string;
  preamble?: string;
  connectors?: any[];
  prompt_truncation?: string;

  max_tokens?: number;

  k?: number;
  p?: number;
  temperature?: number;
  frequency_penalty?: number;
  presence_penalty?: number;
  documents?: Document[];

}

// zhs*
export async function apply(ctx: Context, config: Config) {
  // cl*
  const logger = ctx.logger('chatluna-cohere-playground-adapter')
  const platform = 'cohere'
  const plugin = new ChatLunaPlugin(ctx, config, platform)

  // l*
  class CohereRequester extends ModelRequester {
    constructor(
      private ctx: Context,
      private _config: ClientConfig,
      private _plugin: ChatLunaPlugin
    ) {
      super()
    }

    async* completionStream(
      params: ModelRequestParams
    ): AsyncGenerator<ChatGenerationChunk> {

      const result = await this.completion(params)

      yield new ChatGenerationChunk({
        text: result.text,
        message: new AIMessageChunk({
          content: result.message.content,
          name: result.message.name,
          additional_kwargs: result.message.additional_kwargs
        }),
        generationInfo: result.generationInfo
      })
    }

    async completion(params: ModelRequestParams): Promise<ChatGeneration> {
      const currentInput = params.input[params.input.length - 1]

      if (currentInput._getType() !== 'human') {
        throw new ChatLunaError(
          ChatLunaErrorCode.API_REQUEST_FAILED,
          new Error('CohereRequester only support human input')
        )
      }

      const text = await this._completion(params)

      return {
        text,
        message: new AIMessageChunk({
          content: text
        })
      }
    }

    private async _completion(params: ModelRequestParams) {
      try {
        // const apiKey = await getApiKey(this._config.apiKey);
        const chatResponse = await this.chat(this._config.apiKey, params.model, params.input as BaseMessage[]);

        const results: string[] = [chatResponse]

        return results.join('\n')
      } catch (error) {
        logger.error('An error occurred:', error);
      }
    }

    async chat(apiKey: string, model: string, messages: BaseMessage[]): Promise<string> {
      const message = messages[messages.length - 1].content as string;
      const {preamble, chat_history} = processMessages(messages);
      const bodyJson: ChatRequest = {
        message: message,
        chat_history: chat_history,
        model: model,
        preamble: preamble,
        connectors: [],
        stream: false,
        prompt_truncation: "OFF",

        temperature: config.temperature,
        k: config.k,
        p: config.p,
        frequency_penalty: config.frequency_penalty,
        presence_penalty: config.presence_penalty,
        documents: config.documents || [],
      };

      const response = await this._plugin.fetch("https://api.cohere.com/v1/chat", {
        method: "POST",
        headers: {
          "authorization": `Bearer ${apiKey}`,
          "content-type": "application/json",
        },
        body: JSON.stringify(bodyJson),
      });

      if (!response.ok) {
        throw new Error(`Chat request failed: ${response.statusText}`);
      }

      const data: any = await response.json();
      return data.text;
    }

    dispose(): Promise<void> {
      return Promise.resolve(undefined);
    }

    init(): Promise<void> {
      return Promise.resolve(undefined);
    }
  }

  class CohereClient extends PlatformModelClient {
    platform = platform

    private _requester: CohereRequester

    private _models: {}

    constructor(
      ctx: Context,
      private _config: Config,
      clientConfig: ClientConfig,
      public plugin: ChatLunaPlugin
    ) {
      super(ctx, clientConfig)

      this._requester = new CohereRequester(ctx, clientConfig, plugin)
    }

    async init(): Promise<void> {
      if (this._models) {
        return
      }
      await this._requester.init()

      await this.getModels()
    }

    async getModels(): Promise<ModelInfo[]> {
      if (this._models) {
        return Object.values(this._models)
      }

      const models = await this.refreshModels()

      this._models = {}

      for (const model of models) {
        this._models[model.name] = model
      }

      return models
    }

    async refreshModels(): Promise<ModelInfo[]> {
      return ['command-r-plus', 'command-r', 'command', 'command-nightly', 'command-light', 'command-light-nightly', 'c4ai-aya-23'].map((model) => {
        return {
          name: model,
          type: ModelType.llm,
          maxTokens: 128000,
          supportChatMode: (mode: string) => {
            return mode === 'chat'
          }
        }
      })
    }

    protected _createModel(model: string): ChatLunaChatModel {
      return new ChatLunaChatModel({
        requester: this._requester,
        model,
        modelMaxContextSize: 128000,
        timeout: this._config.timeout,
        maxRetries: this._config.maxRetries,
        llmType: 'cohere',
        modelInfo: this._models[model]
      })
    }
  }

  // sj*
  ctx.on('ready', async () => {
    await plugin.registerToService()

    await plugin.parseConfig((config) => {
      return config.apiKeys.map((apiKey) => {
        return {
          apiKey,
          platform,
          chatLimit: config.chatTimeLimit,
          timeout: config.timeout,
          maxRetries: config.maxRetries,
          concurrentMaxSize: config.chatConcurrentMaxSize
        }
      })
    })

    await plugin.registerClient(
      (_, clientConfig) =>
        new CohereClient(ctx, config, clientConfig, plugin)
    )

    await plugin.initClients()
  })

  // hs*
  async function getApiKey(authorizationForGetKey: string): Promise<string> {
    if (!authorizationForGetKey) {
      throw new Error('Authorization token is not set in environment variables');
    }

    const response = await fetch("https://production.api.os.cohere.com/rpc/BlobheartAPI/GetOrCreateDefaultAPIKey", {
      method: "POST",
      headers: {
        "authorization": authorizationForGetKey,
        "content-type": "application/json",
      },
      body: JSON.stringify({}),
    });

    if (!response.ok) {
      throw new Error(`Failed to get API key: ${response.statusText}`);
    }

    const data: GetKeyResponse = await response.json();
    return data.rawKey;
  }

  function processMessages(messages: BaseMessage[]): Result {
    let lastHumanIndex = messages.length - 1;
    while (lastHumanIndex >= 0 && messages[lastHumanIndex]._getType() !== 'human') {
      lastHumanIndex--;
    }
    if (lastHumanIndex >= 0) {
      messages.splice(lastHumanIndex, 1);
    }

    let preamble = '';
    const nonSystemMessages = messages.filter(message => {
      if (message._getType() === 'system') {
        preamble += message.content + ' ';
        return false;
      }
      return true;
    });

    const chat_history = nonSystemMessages.map(message => ({
      role: message._getType() === 'human' ? 'USER' : 'CHATBOT',
      message: message.content as string
    }));

    return {
      chat_history,
      preamble: preamble.trim()
    };
  }


}
